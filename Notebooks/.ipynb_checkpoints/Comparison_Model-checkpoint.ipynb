{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6f61b33",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-802324160d6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sent' is not defined"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(sent, min_count=1,vector_size= 50,workers=3, window =3, sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "890dac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim.models.Word2Vec?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f603fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "install \n",
    "python 3.8.x\n",
    "jupyter notebook\n",
    "pip install --upgrade gensim\n",
    "pip3 install NlpToolkit-Corpus\n",
    "pip install pandas\n",
    "\n",
    "\n",
    "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
    "tensorflow 2.5.0 requires protobuf>=3.9.2, which is not installed.\n",
    "tensorflow 2.5.0 requires typing-extensions~=3.7.4, which is not installed.\n",
    "tensorflow 2.5.0 requires wrapt~=1.12.1, which is not installed.\n",
    "tensorboard 2.5.0 requires google-auth<2,>=1.6.3, which is not installed.\n",
    "tensorboard 2.5.0 requires protobuf>=3.6.0, which is not installed.\n",
    "tensorboard 2.5.0 requires requests<3,>=2.21.0, which is not installed.\n",
    "tensorboard 2.5.0 requires tensorboard-data-server<0.7.0,>=0.6.0, which is not installed.\n",
    "tensorboard 2.5.0 requires tensorboard-plugin-wit>=1.6.0, which is not installed.\n",
    "tensorboard 2.5.0 requires werkzeug>=0.11.15, which is not installed.\n",
    "tensorflow 2.5.0 requires numpy~=1.19.2, but you have numpy 1.21.2 which is incompatible.\n",
    "tensorflow 2.5.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd83c5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import logging\n",
    "import multiprocessing\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle # because mine was not python=3.8.x\n",
    "\n",
    "#from pattern.en import tokenize\n",
    "from time import time\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94b68261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Corpus.TurkishSplitter import TurkishSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3a911c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/merged.gz\"\n",
    "data = pd.read_pickle(data_path, compression=\"gzip\")\n",
    "data = data.fillna(\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "925035a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Corpus.Sentence.Sentence at 0x28183284b20>,\n",
       " <Corpus.Sentence.Sentence at 0x2817ff9da90>,\n",
       " <Corpus.Sentence.Sentence at 0x281831a0790>,\n",
       " <Corpus.Sentence.Sentence at 0x281831a0af0>,\n",
       " <Corpus.Sentence.Sentence at 0x281831a0e80>,\n",
       " <Corpus.Sentence.Sentence at 0x28182f700a0>,\n",
       " <Corpus.Sentence.Sentence at 0x28182f75ca0>,\n",
       " <Corpus.Sentence.Sentence at 0x2817f59f160>,\n",
       " <Corpus.Sentence.Sentence at 0x2817f59fd00>,\n",
       " <Corpus.Sentence.Sentence at 0x2817f5980a0>,\n",
       " <Corpus.Sentence.Sentence at 0x2817f5986a0>,\n",
       " <Corpus.Sentence.Sentence at 0x2817f59d220>,\n",
       " <Corpus.Sentence.Sentence at 0x2817f59db80>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TurkishSplitter().split(data[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a777e41c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Markalı ürün seferberliği ',\n",
       "  'MÜSİAD Yönetim Kurulu Üyesi Nurettin Nebati , Çin tehdidi dolayısıyla yılbaşından sonra ihracat gelirlerinde ciddi bir düşüş yaşanacağı tahmininde bulunarak , buna karşı ‘markalı ürün’ seferberliği başlatılması gerektiğini bildirdi .'],\n",
       " ['Nurettin Nebati , yaptığı yazılı açıklamada , Türkiye’nin ihracatta rekor üstüne rekor kırmasına karşın , yılbaşından itibaren dış satım gelirlerinde ciddi bir düşüş yaşanacağı öngörüsünde bulundu .'],\n",
       " ['İhracatta istikrarlı büyüme için markalaşmaya odaklanmanın kaçınılamaz bir gerçek olduğu vurgulayan Nebati , ‘İhracatta katma değeri yüksek markalı ürünlerin ağırlığı arttırılabilirse , Türkiye’nin ihracat geliri 2010 yılında yıllık 150 milyar dolara ulaşabilir’ dedi . ',\n",
       "  '',\n",
       "  'Nebati , Türkiye’nin 2003’ten itibaren ihracatta rekor üstüne rekor kırmasına karşın , ihracatın üçte birini gerçekleştiren tekstil ve hazır giyim sanayicileri arasında 2005’le ilgili kaygıların had safhaya ulaştığını dile getirdi',\n",
       "  '']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(sentence).split(\"\\n\") for sentence in TurkishSplitter().split(line)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e06d18af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"ANKARA - Türk Telekom'un indirim reklamları Sanayi ve Ticaret Bakanlığı'na takıldı .\"], [\"Sanayi ve Ticaret Bakanlığı Tüketicinin ve Rekabetin Korunması Genel Müdürlüğü bünyesinde yer alan Reklam Kurulu , Türk Telekom'un 1 Ağustos'tan itibaren yürürlüğe koyduğu yeni tarifelerine ilişkin olarak ' Telefon yüzde 80 ucuzluyor ' sloganını taşıyan TV ve basın reklamlarına ' Tüketici yanıltılıyor ' gerekçesiyle ihtiyati tedbir niteliğinde durdurma cezası verdi .\"], [\"Kurul kararını Türk Telekom'a tebliğ edecek .\"], ['Kurul kesin durdurma kararını üç ay içinde verecek .'], [\"Bu süreç içinde Telekom'un savunması alınacak .\"], ['Ancak tebliğ tarihinden sonra şirketin reklamları durdurmaması halinde , kurulun , şirkete 45 milyar lira para cezası verme hakkı bulunuyor . ', \"Reklam Kurulu , önceki gün , daha önce Tüketici Dernekleri Federasyonu'nun ( TÜDEF ) yanıltıcı tanıtım ve reklam yaptığı , doğruluk ve dürüstlük ilkesine aykırı davrandığı gerekçesiyle yaptığı başvuruyu değerlendirdi . \", \"Reklam Kurulu , Türk Telekomünikasyon A. Ş. ' nin 01.08.2004 tarihinden itibaren uygulamaya başladığı ve ' Telefon konuşmaları yüzde 80 ucuzluyor ' başlığı ile tanıttığı kampanya çerçevesinde abonelerine sunduğu alternatif ücret paketleri ile ilgili reklamlarına ilişkin olarak , Türk Telekomünikasyon A. Ş. ' ye söz konusu reklamları tedbiren durdurma cezası verilmesine karar verdi . \", ' \\' Durdurma \\' kararını veren Tüketicinin ve Rekabetin Korunması Genel Müdürlüğü ve Reklam Kurulu\\'nun başkanı Özcan Pektaş , tüketici derneklerinin başvurusunu değerlendirdiklerini belirterek , \" Türk Telekom\\'un reklamlarında tüketicilerin yanıltılmasına yönelik ifadelerin olduğu tespit edildi . Zaman zaman basında da dile getirildiği gibi açıklanan tarifelerde indirim değil bindirme yapılıyor . Tüketicilerin yanıltılmasını önleyebilmek için ihtiyati tedbir olarak reklamları durdurma kararı alındı \" diye konuştu . ', 'Ceza 95 milyar liraya çıkabilir ', 'Pektaş , \\' İndirim olmadığını siz nasıl tespit ettiniz \\' sorusuna \" Mevcut tarife ile yeni tarife ortada \" yanıtını verdi .'], [\"Kurulun aldığı kararın Türk Telekom'a hafta başında tebliğ edileceği öğrenildi .\"], [\"Karar ' ihtiyati durdurma ' şeklinde verilmiş olsa da , tebliğin eline ulaşmasıyla Türk Telekom'un sözkonusu reklamları durdurması gerekiyor . \", 'Kurul kesin durdurma kararını ise üç ay içinde verecek .'], [\"Bu süreç içinde Türk Telekom'un savunması alınacak .\"], [\"Edinilen bilgilere göre kurul , 14 Eylül'de yapacağı toplantıya Türk Telekom yetkililerini davet \", 'edecek .'], [\"Ancak Reklam Kurulu'nun şirkete para cezası dahi uygulama hakkı var . \", 'Türk Telekom , kurulun kararının tebliğ edilmesinin ardından söz konusu reklamlara devam ederse para cezası gündeme gelecek .'], ['Reklam Kurulu , tebliğin gereğini yerine getirmezse şirkete 45 milyar lira , reklamlara devam etmesi halinde ise 95 milyar lira para cezası verecek .'], [\"Öte yandan , Tüketicinin ve Rekabetin Korunması Genel Müdürlüğü , 4077 sayılı Tüketicinin Korunması Yasası'nın 6. maddesi uyarınca , Türk Telekom'un tarifelerindeki sabit ücretle ilgili olarak da ' hizmet vermeden ücret almak ' konusunda inceleme başlattı .\"]]\n",
      "[[\"TAHRAN - İran Cumhurbaşkanı Muhammed Hatemi , yabancı şirketlerden gelen tüm itirazlara rağmen , ülkenin ikinci özel sektör cep telefonu lisansını Turkcell'e vereceklerini ve buna ilişkin anlaşmanın yakında imzalanacağını söyledi .\"], ['Hatemi , 3 milyar dolarlık anlaşmanın 1979 yılındaki İslam devriminden sonra ülkeye yapılacak en büyük yatırım olduğunu ve bunun ', \"İran'ın çıkarlarına olacağını kaydetti .\"], ['Hatemi yapılan haftalık kabine toplantısından sonra yaptığı açıklamada , \" Turkcell ile yapılacak olan söz konusu anlaşmanın yakın bir gelecekte imzalanacağını düşünüyorum \" diye konuştu .'], [\"Turkcell'den yapılan açıklamada ise İran ile yapılan lisans sözleşmesi görüşmelerinin yavaş geliştiği belirtildi . \", '']]\n",
      "[[\"Türkiye'den zam kararıyla ilgili yapılan açıklamada zammın ardında , hükümetin geçtiğimiz hafta başında sigaralardan alınan vergilerle ilgili sistemi tümüyle değiştirmesiyle ilgili gelişmeler bulunduğu belirtildi . \", 'Yeni sistemde Türkiye pazarında orta ve uygun fiyat kategorilerinde yer alan uluslararası sigaraların orantısız ve adeta ceza niteliği taşıyan bir biçimde vergilendirildiğine işaret edilerek , buna karşılık Tekel ürünlerine ise düşük vergilendirme ile koruyucu bir sistem uygulandığı öne sürüldü . ', \" ' Adil bir sisteme dönün ' \", 'Yeni vergi politikasının Türk sigara pazarına ayırımcılık yapılmış anlamına geldiğini belirten JTI Başkan Yardımcısı ve Türkiye Genel Müdürü Servisimin Cömert Birced , sözlerini şöyle sürdürdü : \" Hükümetin yeni vergi politikası karşısında bu bizim ilk aşamadaki asgari tepkimizdir . Yeni vergi sisteminin şirketimiz ve genelde Türk sigara pazarı üzerindeki tahrip edici etkilerini belirlemeye devam edeceğiz . Bununla birlikte hükümeti durumu gözden geçirmeye ve tüm tarafların eşit şekilde değerlendirildiği adil bir vergi sistemine geri dönmeye davet etmek için zamanın hiç de erken olmadığı görüşündeyim', '']]\n",
      "[[\"Ankara Sanayi Odası ( ASO ) Başkanı Zafer Çağlayan , Türkiye'nin bir numaralı sorunu olan istihdam için ' hızlandırılmış ' önlemler alınması gerektiğini söyledi .\"], [\"DSP Genel Başkanı Zeki Sezer , tüketim çılgınlığına işaret ederek göz göre göre banker faciasına benzer bir ' kart faciası'na gidildiğine dikkat çekti .\"], [\"Çağlayan , genel başkan değişimi nedeniyle DSP Genel Başkanı Zeki Sezer'i , ardından da eski Genel Başkan Bülent Ecevit'i ziyaret etti .\"], [\"Çağlayan , Sezer'i ziyareti sırasında Türkiye'nin en büyük sıkıntısının işsizlik ve cari açık olduğuna işaret ederek , cari açığın finanse edilebilmesi için Türkiye'ye doğrudan yabancı sermayeyi çekmek gerektiğini söyledi . \", 'Kredi kartı uyarısı ', 'ASO Başkanı Zafer Çağlayan , \" Sanayici kredi bulamazken , insanların cebine patlamaya hazır bomba gibi kredi kartı konuluyor . Tüketim çılgınlığı sorun yaratabilir \" uyarısı yaptı .'], ['Sezer ise yatırıma dayanmayan büyümenin sağlıklı olmadığını vurguladı .'], ['Dış ticaret açığının 30 milyar dolar gözüktüğüne işaret eden Sezer , \" Bu , çok sağlıklı gidiş değil . Bu nedenle tedbir alınmalı . Tüketim çılgınlığına getirilecek sınırlamanın da bir yolu olabileceğini düşünüyorum . Banker faciasına benzer bir kart faciasına göz göre göre gidiliyor gibi \" ifadesini kullandı .'], ['Zafer Çağlayan , Ecevit\\'i ziyareti sırasında da , \" Geçmişte başbakanlık ve diğer görevlerinizde hakkınızda en ufak şaibe ve dedikodu söz konusu olmadı . Darısı herkesin başına \" dedi', '']]\n",
      "[['Yatırım yapan kazanacak ', \"Anadolu Hayat Emeklilik Genel Müdürü Mustafa Su , Bireysel Emeklilik Sistemi'nde ( BES ) katılım paylarının hangi oranda yatırıma yönlendirildiğinin önemli olduğunu söyledi .\"], ['Katılımcıların kesinti oranlarına dikkat etmesi gerektiğini belirten Su , sistemin cazip hale gelebilmesi için katılım paylarının azami ölçüde yatırıma yönlendirilmesi gerektiğini ifade etti .'], ['Anadolu Hayat Emeklilik olarak katkı paylarından sadece yüzde 2.4 oranında kesinti uyguladıklarını dile getiren Mustafa Su , \" Katılımcıların yatırdıkları her 100 liralık katkı payının 97.6 lirasını yatırıma yönlendirerek daha kazançlı çıkmalarını sağlıyoruz . Sistemin başladığı günden bu yana düşük kesinti prensibini başarıyla uyguladık \" dedi . ', 'BES\\'te uzun vadede hem katılımcıların , hem şirketlerin , hem de ülke ekonomisinin kazançlı çıkacağını belirten Mustafa Su şöyle konuştu : \" Bilindiği gibi , bireysel emeklilik sistemi hem katılımcıya hem de şirketlere uzun vadede kazanç vaat etmektedir . Emeklilik şirketleri ne kadar çok fedakârlık yaparsa , katılımcıların menfaati o kadar artacaktır . Hedefimiz düşük kesinti stratejisiyle sistemi cazip hale getirmektir . \" ', '', \" ' Kesintiye dikkat ' \", 'AnadoluHayatEmeklilik GenelMüdürüMustafaSu , BES katılımcılarına şu uyarılarda bulundu : \" Bireysel emekliliğe titizlikle hazırlandık . Amacımız katılımcıların menfaatlerine uygun planlar sunmak , bu amaçla kesinti oranlarını minimumda tutarak katkı paylarının en üst seviyede yatırıma yönlendirilmesini ve yüksek getiri sahibi olmalarını sağlamaktır . ', 'Katılımcıların dikkatli olması gereken bu hususları özellikle belirtmek isterim . Bu arada katılımcılar yatırdıkları her 100 birim katkı payının ne kadarı kesintiye gidiyor , ne kadarı yatırıma yönlendiriliyor , sorusunu mutlaka sormalı . \" ', \"AXA OYAK Sigorta'ya 2004 Tüketici Ödülü \", \"Grand Cevahir Otel'de düzenlenen ' Tüketici Zirvesi'nde Devlet Bakanı Güldal Akşit ve Tarım ve Köyişleri Bakanı Sami Güçlü'nün katılımıyla ' Tüketici 2004 Kalite Ödülleri ' sahiplerini buldu .\"], ['Tüketici Dergisi bu zirveden önce düzenlediği kalite anketiyle bir yıl boyunca iki değişik kanaldan Türk halkının marka tercihlerini araştırdı . ', 'İlk aşamada yaklaşık 38 bin kişi ile birebir anket gerçekleştirildi .'], [\"Elde edilen sonuçlar daha sonra , Tüketici Dergisi'nin internet sitesinden gelen oylarla birleştirildi ve Türkiye'de tüketicinin kalitesine en çok güvendiği markalar belirlendi . \", \"Marka araştırmasının ' Sigorta Şirketleri ' dalındaki birincilik ödülü AXA OYAK'ın oldu .\"], [\"Pek çok firmanın faaliyet gösterdiği Türk sigorta sektörü içerisinde yüzde 18'lik bir oyla alanında Türkiye'nin kalitesine en güvenilen markası olan AXA OYAK , en yakın rakibi ile arasında yüzde 5'lik bir fark yarattı . \", \"Genel Sigorta ' değişim ve gelişim'e açık \", 'Genel Sigorta çalışanları Maslak Princess Otel\\'de \" Motivasyon Toplantısı\\'nda buluştu . 2003 yılında şirket genelinde başlatılan \\' değişim ve gelişim \\' workshop projesinin devamı olan bu çalışmaya genel müdürlük ve tüm bölge müdürlüklerinden yönetici ve çalışanlar katıldı . Genel Sigorta Genel Müdürü Hulusi Taşkıran\\'ın açılış konuşmasıyla başlayan toplantıda genel müdür yardımcıları Serdar Gül ve Didem Bulut hazır bulundu . ', '', 'Çalışanlara özel bilgi ', \"Pazarlama , Eğitim ve Reklam , Halkla İlişkilerden Sorumlu Genel Müdür Yardımcısı Didem Bulut , katılanlara Genel Sigorta'nın sektördeki en son durumunu yansıtan bir sunumla şirketin sektör içindeki konumu , sermaye durumu ve finansal yapısı ile ilgili bilgileri aktardı . Şirket genelinde kaliteli hizmet sunumuna önem verildiği vurgulanarak , geçen yıldan bu yana kalite iyileştirme faaliyetleri hakkındaki grup workshop'lar ve alınan aksiyonlar irdelendi . Toplantıda şirketin en son reklam çalışması olan ' kâğıt ötesi sigortacılık ' temasının işlendiği reklam görseli tanıtıldı . Bu arada şirket çalışanlarının önem verdiği öneri sistemi de değerlendirildi . Öneri sistemine gönderilen önerilerin değerlendirilmesi sonunda pazarlama yetkilisi Rengin Kızılkaya birincilik ödülü aldı . \", \"Başak'ın balığı konuştu \", \"Digiturk'ün 33 radyo ve ekstra müzik kanalındaki balıklar Başak Sigorta'nın reklamında konuşuyor \", '', \"Digiturk'ün 33 radyo ve ekstra müzik kanalını açtığınızda karşınıza gelen akvaryumdaki balıkların Başak Sigorta reklamında yaptıklarını gördüyseniz şaşırmayın . Aquavision'un deniz dibinin büyüleyici atmosferini ekrana yansıttığı bu yeni uygulama ile stresten arınmak için Kızıldeniz'e veya Maldivler'e gitmenize gerek yok . Akmerkez'de kurulan 20 litrelik akvaryumdan görüntülerin yayımlandığı Digiturk'ün ekstra müzik ve radyo kanallarından deniz altının gizemli dünyasını keşfedebilirsiniz . \", 'Buraya ilk reklamveren olan Başak Sigorta , huzur ve güveni çağrıştıran bir ortamda reklamlarının müşteriye ulaşmasını amaçlıyor . Aquavision olarak adlandırılan reklam projesinde , akvaryumdaki balıklar birbirleriyle konuşma balonlarıyla konuşturuluyor ve diyaloglarda şirket isimleri geçiyor . ', 'Bu arada ekranda görülen gerçek akvaryumda 21 cins balık ve 100\\'ün üzerinde deniz canlısı yaşıyor . Başak Sigorta Reklam Müdürü Burcu Dinçer , \"'], ['İnsanlar çağın gereği artık evlerine gittiklerinde daha sakin ve huzurlu bir ortam arıyor .'], ['Digitürk radyo kanallarının 33 kanalından herhangi birini açtığınızda hem müzik dinliyorsunuz , hem de akvaryumda balıkları seyrediyorsunuz .'], ['Halkımızın sevebileceği projelerde yer almak istiyoruz \" dedi . ', \"Melodi de ' Batı'lı \", \"Batı Sigorta , yat yarışlarının tanınmış isimlerinden olan ' Melodi ' teknesine iki yıldır sponsor olarak destek veriyor . Batı Sigorta'yı bayrağını taşıyarak yarışlarda tanıtan ' Melodi ' teknesi , geçtiğimiz yıllarda olduğu gibi 2004 yılında da yurtiçi ve yurtdışı yarışlarda başarılara damga vurmak için yarışacak . \", 'Eğitim hep sürecek ', 'Tekstilbank şube müdürleri ile Acıbadem Sağlık ve Hayat Sigorta yetkilileri , eğitim çalışmasında bir araya geldi . Acıbadem Sigorta ve Acıbadem Sağlık Grubu tanıtım filmleri gösterildikten sonra , toplantının açılış konuşmasını Acıbadem Sigorta Pazarlamadan Sorumlu Genel Müdür Yardımcısı Gülsultan Doğan yaptı . ', '', 'Hedef büyük ', \"Acıbadem Sigorta'nın üretim rakamları ve hedeflenen veriler Satıştan Sorumlu Grup Müdürü Serpil Erden tarafından , Acıbadem Sigorta ürünleri ise Projeler ve Organizasyon Grup Müdürü Timur Kaya tarafından Tekstilbank şube müdürlerine aktarıldı . Acıbadem Sigorta ve Tekstilbank işbirliğinin şube kârlılığı Gülsultan Doğan tarafından anlatıldıktan sonra , soruları Tıbbi Koordinasyon Müdürü Dr . Tuğrul Özseçen yanıtladı . \", '']]\n",
      "[['Ziraat Bankası , Hazine tarafından belirlenecek tarihte başlayacak olan üçüncü taksit nema ödemeleriyle ilgili kurum ve işyeri toplu başvurularının , 18 Ağustos’tan itibaren kabul edileceğini bildirdi . ', 'Tasarrufu teşvik işyeri sicil numaları olan ve elektronik posta adresi uzantıları . k21.tr , . edu . tr , . com . tr , . gov . tr , . mil . tr , . pol . tr ve . bel . tr olan özel kuruluşlar ile kamu kurum ve kuruluşları personelleri , üçüncü taksit nema ödemelerini işyerleri aracılığıyla alabilecekler . ', '', 'Daha önceki taksit ödemelerinde olduğu gibi kurum ve işyeri aracılığıyla talepte bulunan hak sahiplerinin ödemeleri , başvuru tarihinden itibaren en geç üç gün içinde yapılacak . ', '', 'Kurumu aracılığıyla başvurmayan hak sahiplerinin ise bir aylık takvim içinde sıralarını bekleyecekleri bildirildi . ', '', 'Kurum ve işyerleri , ünvanlarını taşıyan elektronik posta adresi ile birlikte en son kesinti ve katkı tutarlarını yatırdıkları Ziraat Bankası şubelerine başvuracaklar . ', '', 'Kurum ve işyeri yetkililerine üçüncü taksit nema ödemesi yapılabilmesi için son bir ay içinde verilmiş olan kamu kurum ve kuruluşları için resmi görevlendirme / yetki yazısı , diğer kuruluşlar için noter takdikli yetki belgesi ve imza sirküleri , işyerlerine ait tasarrufu teşvik işyeri sicil numarası , kurum veya işyeri irtibat telefonu ve geçerli e - posta adresiyle birlikte başvurmaları gerekiyor . ', '', 'Banka tarafından hazırlanacak nema üçüncü taksit talep dosyaları , kurum veya işyerlerinin e - posta adreslerine iletilecek .'], ['Bu dosya yalnızca Ziraat Bankası’nın internet adresinden kurum veya işyerlerine iletileceği bildirildi . ', '', 'Ziraat Bankası’na gelen başvuruların , en kısa sürede işleme alınıp kurum veya işyerlerinin e - posta adreslerine olumlu ya da olumsuz bilgi verileceği kaydedildi', '']]\n",
      "[['Japan Tobacco International ( JTI ) , geçen hafta özel tüketim vergisi ( ÖTV ) oranlarında yapılan değişikliğin ardından , orta fiyat kategorisinde yer alan ürünü Winston sigarasının fiyatına yüzde 26.1 ile yüzde 27.3 arasında artırdı . ', 'Düzenleme sonrası 2 milyon 300 bin lira olan Uzun Winston ve Uzun Winston Light sigaralarının fiyatı yüzde 26.1 oranında artışla 2 milyon 900 bin liraya çıktı . ', \"Kısa Winston'ın , Box , Soft , Light ve Superlight çeşitlerinin fiyatları da yüzde 27.3 oranında artışla 2 milyon 200 bin liradan 2 milyon 800 bin liraya çıktı\", '']]\n",
      "[['Piyasada petrol gerginliği ', ' ', ' ', 'Devam eden cari açık endişesi , petrol fiyatlarındak yüksek seyir ve uluslararası borsalardaki olumsuzluklar piyasaları rahatsız etti .'], ['Borsa , günü sadece 6 puanlık yükselişle 18 bin 832 puandan tamamladı .'], ['Dövizde gevşeme yaşanırken bono faizlerinde de düşüş vardı . ', 'Piyasaların en önemli gündem maddesini üst üste rekorlar kıran petrol fiyatlarının seyri oluşturdu .'], ['Bununla birlikte beklentilerin üzerinde çıkan cari açık ve bu konuda alınan önlemler yakından izlendi . ', '', 'Güne bu tedinginliklerle başlayan Borsa , satıcılı ve sıkışık bir seyir izledi .'], [\"Yeni para girişinin yaşanmadığı Borsa'da endeks 18 bin 700 puan seviyelerine kadar çekildi .\"], ['İMKB Ulusal - 100 Endeksi 76 puanlık düşüşle birinci seansı 18 bin 750 puandan tamamladı .'], ['Hisse senetleri yüzde 0.4 oranında değer yitirdi .'], ['Endeks , seans içinde en düşük 18 bin 652 puan olurken , en yüksek olarak açılıştaki 18 bin 857 puanı gördü .'], [\"1. seansta işlem gören toplam 292 hisse senedinden 94'ü değer kazandı , 140'ı değer yitirdi , 58 hissenin fiyatında değişiklik olmadı .\"], ['Seansta , 175 trilyon 866 milyar 185 milyon liralık işlem hacmi oluştu .'], ['1. seansta , Doğan Holding , Doğan Yayıncılık , Kardemir ( D ) , Yapı ve Kredi Bankası ve İş Gayrimenkul Yatırım Ortaklığı en fazla işlem gören hisse senetleri oldu . ', '', 'İkinci seansta bir miktar toparlanma yaşandı .'], ['İMKB Ulusal - 100 Endeksi 6 puanlık yükselişle günü 18 bin 832 puandan tamamladı .'], ['Hisse senetleri yüzde 0.04 oranında değer kazandı . ', '', 'Dövizde vergi ödemeleri nedeniyle gerileme yaşandı .'], ['Öğleden sonra ise bir miktar yükseliş vardı .'], ['Serbest piyasada dolar 1.462.0 lira , euro 1.804.0 liradan haftaya başladı . ', 'Merkez Bankası dolar kapanış kurunu alış 1.452.393 lira , satış 1.459.398 lira olarak açıkladı .'], ['Euronun alış kuru 1.793.124 lira , satış kuru ise 1.801.773 lira oldu . ', '', 'Bono piyasasında da faizler geriledi .'], [\"En çok işlem gören 22 Şubat 2006 vadeli tahvilin basit faizi yüzde 26.65'ten , bileşik faizi yüzde 25.07'den kapandı .\"], ['Bu kağıdın aynı gün valörlü işlemlerinin bileşik faizi , Cuma günkü kapanışa göre 0.21 puan düştü .'], ['Bu tahvilin aynı gün valörlü işlemlerinin Cuma günkü kapanışında , basit faizi yüzde 26.91 , bileşik faizi yüzde 25.28 olmuştu', ' ', '']]\n",
      "[['SSK’ya pahalı ilaç satarak devleti zarara uğrattığı gerekçesiyle hakkında soruşturma başlatılan Roche’un İstanbul’daki genel müdürlüğüne baskın düzenleyen polis , ilaç alım ihalesine katılmak isteyen Roche’nin kendi ana bayilerine gönderdiği bir yazı ile ‘ihaleye katılırsanız bayiliğiniz iptal edilir’ şeklinde tehdit ettiği belgesine ulaştı . ', '', 'Yazı ile anabayilerini SSK’a ihalelerin teklif vermelerini engelleyen Roche firmasının tek başına ihalelerde fiyat belirlemeyi sağladığı ortaya çıktı .'], ['Polis , baskınlarda ele geçirdiği 6 koli evrak ile bilgisayar kayıtların incelemeyi sürdürüyor .'], ['Ancak baskında ele geçen muhasebe kayıtların SSK ihaleleri ile ilgili bölümünün silindiği bildirildi .'], ['Ankara’da Beşer firmasına yapılan baskında da ele geçen 20 koli evrakında incelenmek üzere İstanbul’a gönderileceği bildirildi . ', '', 'Roche’nin işten çıkardığı yetkililerin ihbarıyla ortaya çıkan SSK ilaç ihale skandalı ihaleye fesat karıştırmak suçlaması yeni boyut ortaya çıktı .'], ['İstanbul Organize Şube Müdürlüğü ekiplerince önceki gün basılarak incelenmek üzere bazı evraklarına el konulan Roche’in bayilerine bir yazı göndererek ihalelere katılmamasını aksi halde bayiliklerinin iptal edileceğini bildirdiği belirlendi . ', '', 'Roche firmasının bayilerine 88 milyon liradan sattığı kanser ilacını SSK’ya 230 milyon liradan satarak yaklaşık yarım milyon doların üzerinde bir haksız kazanç elde edildiği tahmin ediliyor . ', '', 'Roche ilaç firmasında ki ilaç yolsuzluğunu soruşturan İstanbul Cumhuriyet savcısı Nazmi Okumuş’un talimatıyla önceki gün Levent’de ki firmanın genel merkezine baskın yapan Organize Şube Müdürlüğü ekipleri 6 koli evrak ele geçirdi .'], ['Evrakların dökümleri yapıldıktan sonra savcılığa gönderileceği bildirildi .'], ['Roche Yönetim Kurulu Başkanı Faruk Yöneyman soruşturmayı yürüten İstanbul Cumhuriyet Savcısı Nazmi Okumuş’a önceki gün ifade verdi .'], ['Yöneyman’ın ifadesinde , ‘İlaç satış ihalelerinde hiçbir usülsüzlük olmadı .'], ['İlaçların fiyatlarını SSK’ya sunduk .'], ['Onlarda kabul ettiler’ dediği bildirildi . ', '', 'Ankara’dan 15 koli evrak geldi', '', 'SSK’yı fahiş fiyatla ilaç satarak zarara uğrattığı iddiasıyla İstanbul Cumhuriyet Savcısı Hüseyin Nazmi Okumuş tarafından hakkında soruşturma başlatılan Roche firmasının 2003-2004 yıllarına ait ihale dosyaları , envanter ve şirket kayıtlarından oluşan 15 koli evrak , Ankara’dan , Organize Suçlarla Mücadele Şube Müdürlüğü’ne getirilerek incelemeye alındı .'], ['Sağlık Bakanlığı’nda ve Roche firmasının ilaçları sattığı Beşer Ecza Deposu ile Başkent Hastanesi’nde bulunan ihale dosyaları ve faturalardan oluşan 15 koli dolusu evrak da dün Ankara’dan bir polis minübüsüyle incelenmek üzere İstanbul’a getirildi', '']]\n",
      "[['İzmir Adnan Menderes Havalimanı’nda bir ‘güvenlik’ eziyeti yaşanıyor .'], ['THY , transit yolcuları ve iç hat yolcularını ayrı otobüslere bindirirken , yolcular 1 saat süren bir işlemle tek tek sayılıyor . ', '', 'İZMİR Adnan Menderes Havalimanı’nda yurt dışı bağlantılı transit yolcuların gümrüğe götürülmek üzere iç hat yolcularından ayrı otobüse bindirilmesi ve bu sırada yaşanan sorunlar nedeniyle yolculuğun yarım saatle bir saat arasında uzuyor .'], ['Yolcular , bu işlemler sırasında tek tek sayıldıklarını söyleyip tepki gösterirken , Türk Hava Yolları ( THY ) yetkilileri , güvenlik nedeniyle bu işlemi yaptıklarını belirtti . ', '', 'Yurt dışından İzmir’e bilet alan yolcular , İstanbul’da aktarma yapıp Türk Hava Yolları’nın iç hatlar uçağına biniyor .'], ['Bu nedenle normal olarak İstanbul’dan İzmir’e gelen uçakta normal iç hat yolcuları olduğu gibi , yurt dışından gelen yolcular da yeralıyor .'], ['Transit yolcuların yurtiçine giriş işlemi de bu nedenle İzmir’de Adnan Menderes Havalimanı Dış Hatlar Terminali’nde pasaport ve bagaj kontrolu yapılıyor .'], ['Yurt dışından gelen yolcular bundan sonra Türkiye’ye giriş yapıyor .'], ['Uçak , İzmir Adnan Menderes Havalimanı’na indiğinde iç hat yolcuları ile Transit Yolcular ayrı otobüslere bindiriliyor .'], ['Normal yolcular iç hatlar çıkış terminaline , transit yolcular da dış hatlar terminaline pasaport kontrolüne götürülüyor . ', '', 'Yolcuların birbirlerinden ayrılıp ayrı otobüslere bindirilmeleri sırasında uçakta sorun yaşanıyor .'], ['Türk Hava Yolları’nın bu işlemlerle ilgili yaptıkları anonsları yolcular genellikle anlamıyor ve sorun yaşanıyor .'], ['Yanlış otobüslere binmeler olduğu gibi , THY görevlilerinin de kendilerine yardımcı olmadıkları öne sürülüyor .'], ['Uçakta ve otobüslere binildikten sonra yapılan sayımlarda yanlış otobüslere binildiği için transit yolcu sayısı genellikle birbirini tutmadığından , görevliler yeniden teker teker sayım yapmak zorunda kalıyor . ', '', 'Yolcular ve seyahat acentaları bu kargaşalık nedeniyle yarım saatle bir saat arasında gecikmeler yaşandığını vurguladı .'], ['Bu konuda tur organizatörleri , ‘Yolcular uçağın içinde veya otobüslerde anlamsız bekletiliyor .'], ['Klimalar ve havalandırma kapatıldığı için uçağın içi sıcak oluyor .'], ['Yapılan anons ise anlaşılmıyor . ', '', 'İzmir Ticaret Odası Başkanı Ekrem Demirtaş , bu sorunu sık sık yaşadığını belirterek , biraz dikkat ve özenle sorunun çözülebileceğini savundu .'], ['Demirtaş , gümrüklü yolcularla , iç hatlar yolcularının birbirlerine karışmaması için personelin ellerinde bir uyarı pankart ile yolculara yön göstermesi gerektiğini ifade etti . ', '', 'THY : Güvenlik için yapıyoruz', '', 'THY yetkilileri mevcut uygulamayı yapmak zorunda olduklarını ifade etti .'], ['Sayım işleminin güvenlik açısından gerekli olduğunu vurgulayan yetkililer , yolcuların isim isim sayımının kendileri için de sıkıntı yarattığını ancak mevcut imkanlar dahilinde başka alternatiflerinin olmadığını belirterek şöyle dedi : ', '', '‘Sayım işlemindeki amaç , yasadışı yollardan girişi önlemek .'], ['Yolcuları teker teker saymazsak emniyet yetkilileri THY görevlileri hakkında soruşturma açar .'], ['İsimleri okunan bazı yolcular bilerek cevap vermiyor ya da soruyu anlamamazlıktan geliyor . ', '']]\n",
      "[[\"Günlerdir olumsuz haberler nedeniyle yükselişini sürdüren petrol piyasalarının ateşi , Venezüella ve Suudi Arabistan'dan gelen olumlu haberlerle düşme eğilimine girdi .\"], ['Bu sabah uluslararası borsalarda petrol fiyatları 46.91 ile yeni bir rekor kırmıştı . ', \"Gün içinde New York Ticaret Borsası'nda 46.91 dolarla tarihinin en yüksek değerini gören hafif türü ham petrolün varil fiyatı , Venezüella'daki referandum sonuçlarının açıklanmasının ardından 46.20 dolar seviyesine geriledi . \", '', \"Londra Uluslararası Petrol Borsası'nda işlem gören Brent türü ham petrolün varil fiyatı ise Venezüella'dan gelen haberler sonrasında 43 sent gerileyerek 43.40 dolar seviyesine indi . \", '', \"Venezüella'nın günlük 2.6 milyon varil seviyesinde bulunan petrol arzının Devlet Başkanı Hugo Chavez'in referandumu kaybetmesi halinde yandaş işçilerin eylemleri neticesinde kesintiye uğrayacağı korkusu , uzmanlarca petrol fiyatlarında son günlerde yaşanan rekor yükselişlerin nedeni olarak gösteriliyordu . \", '', \"CHAVEZ'DEN İSTİKRAR SÖZÜ\", '', \"Venezüella'da hafta sonu gerçekleştirilen referandumda zaferini ilan eden Devlet Başkanı Hugo Chavez , zafer konuşmasında petrol piyasasında istikrar sözü verdi . \", '', \"“Hükümetim adına OPEC'e garanti ederim ki dünya petrol piyasasının istikrarı sağlanacak” diyen Chavez , Orta Doğu haricindeki en büyük petrol rezervlerine sahip ülkesiyle ilgili endişelerin azalmasını sağladı . \", ' ', '25-30 DOLAR', '', \"Başkent Riyad'da yayınlanan bir gazeteye açıklamalarda bulunan Suudi Arabistan Veliaht Prensi Abdullah ise petrol fiyatlarını 25-30 dolar seviyesine çekmeyi hedeflediklerini kaydetti . “Fiyatları 25-30 dolar seviyesine düşürmek için petrol sahalarının izin verdiği ölçüde maksimum pompalama yapacağız” diyen Veliaht Prens , rekor seviyelerde gezen fiyatların gevşetilmesi adına ülkesinin üzerine düşeni yapmayı sürdüreceğini söyledi . \", '', '50 DOLAR BEKLENTİSİ', '', \"Son gerçekleşen yükselişlerle birlikte ham petrol fiyatları New York Ticaret Borsası'nda , 1 yıl öncesine göre yüzde 50'nin üzerinde değer kazanmış oldu . \", '', 'Venezuella devlet petrol şirketi PDVSA Başkanı Ali Rodriguez ham petrol fiyatlarının bu hafta içinde 47-48 dolarları görebileceğini belirterek , “50 dolar seviyesi bir mıknatıs gibi piyasaları çekiyor .'], ['Sanırım bu seviyeye bir deneme olacak” diye konuştu', '']]\n",
      "[['Markalı ürün seferberliği ', 'MÜSİAD Yönetim Kurulu Üyesi Nurettin Nebati , Çin tehdidi dolayısıyla yılbaşından sonra ihracat gelirlerinde ciddi bir düşüş yaşanacağı tahmininde bulunarak , buna karşı ‘markalı ürün’ seferberliği başlatılması gerektiğini bildirdi .'], ['Nurettin Nebati , yaptığı yazılı açıklamada , Türkiye’nin ihracatta rekor üstüne rekor kırmasına karşın , yılbaşından itibaren dış satım gelirlerinde ciddi bir düşüş yaşanacağı öngörüsünde bulundu .'], ['İhracatta istikrarlı büyüme için markalaşmaya odaklanmanın kaçınılamaz bir gerçek olduğu vurgulayan Nebati , ‘İhracatta katma değeri yüksek markalı ürünlerin ağırlığı arttırılabilirse , Türkiye’nin ihracat geliri 2010 yılında yıllık 150 milyar dolara ulaşabilir’ dedi . ', '', 'Nebati , Türkiye’nin 2003’ten itibaren ihracatta rekor üstüne rekor kırmasına karşın , ihracatın üçte birini gerçekleştiren tekstil ve hazır giyim sanayicileri arasında 2005’le ilgili kaygıların had safhaya ulaştığını dile getirdi', '']]\n"
     ]
    }
   ],
   "source": [
    "for idx, line in enumerate(data):\n",
    "    print([str(sentence).split(\"\\n\") for sentence in TurkishSplitter().split(line)])\n",
    "    if idx > 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa91dda3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29d2b9c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46ff5e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_for_char_based(text, char_set, min_token=4, min_char=15, unk_eliminate_ratio=0.3, split=True):\n",
    "    '''\n",
    "    Takes a chunck of text, splits them into sentences then splits sentences into tokens if split True.\n",
    "    char_set = list of valid chars\n",
    "    min_token = min token size of a sentence\n",
    "    min_char = min character length of a sentence\n",
    "    unk_eliminate_ratio = eliminates the sentence if unknown char ratio is bigger this (between 0-1)\n",
    "    '''\n",
    "    results = []\n",
    "    from Corpus.TurkishSplitter import TurkishSplitter\n",
    "    sentences = TurkishSplitter().split(text)\n",
    "    translator = str.maketrans({chr(10): ' ', chr(9): ' '})\n",
    "    for sentence in sentences:\n",
    "        sentence = str(sentence)\n",
    "        sentence = sentence.translate(translator)\n",
    "\n",
    "        if(len(sentence) < min_char):\n",
    "            continue\n",
    "        \n",
    "        unks = [1 if (c not in char_set and c != \" \") else 0 for c in sentence]\n",
    "        unk_ratio = sum(unks) / len(unks)\n",
    "        if(unk_ratio > unk_eliminate_ratio):\n",
    "            continue\n",
    "        \n",
    "        if(len(sentence.split(\" \")) < min_token):\n",
    "            continue\n",
    "        \n",
    "        if(split):\n",
    "            sentence_split = sentence.split(\" \")\n",
    "            results.append(sentence_split)\n",
    "        else:\n",
    "            results.append(sentence)        \n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb15b926",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pattern'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-2490ee92e45d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0men\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pattern'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b40bd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', raw_html)\n",
    "    return cleantext\n",
    "\n",
    "class MySentences(object):\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        data = pd.read_pickle(data_path, compression=\"gzip\")\n",
    "        self.data = data.fillna(\" \")\n",
    "\n",
    "    def __iter__(self):\n",
    "        for text in self.data:\n",
    "            cleaned_text = cleanhtml(text)\n",
    "            for sentence in TurkishSplitter().split(cleaned_text):\n",
    "                for line in sentence.split(\"\\n\"):\n",
    "                    sline = line.strip()\n",
    "                    if sline == \"\":\n",
    "                        continue\n",
    "                    sline = sline.lower()\n",
    "                    if not sline.isalpha():\n",
    "                        continue\n",
    "                    #tokenized_line = ' '.join(tokenize(rline))\n",
    "                    #is_alpha_word_line = [word for word in\n",
    "                    #                      tokenized_line.lower().split()\n",
    "                    #                      if word.isalpha()]\n",
    "                    yield sline\n",
    "                    \n",
    "                    \n",
    "\"\"\"\n",
    "class MySentences(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    "\n",
    "    def __iter__(self):\n",
    "        for root, dirs, files in os.walk(self.dirname):\n",
    "            for filename in files:\n",
    "                file_path = root + '/' + filename\n",
    "                for line in open(file_path):\n",
    "                    sline = line.strip()\n",
    "                    if sline == \"\":\n",
    "                        continue\n",
    "                    rline = cleanhtml(sline)\n",
    "                    tokenized_line = ' '.join(tokenize(rline))\n",
    "                    is_alpha_word_line = [word for word in\n",
    "                                          tokenized_line.lower().split()\n",
    "                                          if word.isalpha()]\n",
    "                    yield is_alpha_word_line\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "addd9958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-17 19:42:41,933 : INFO : collecting all words and their counts\n",
      "2021-08-17 19:42:41,934 : INFO : collected 0 word types from a corpus of 0 raw words and 0 sentences\n",
      "2021-08-17 19:42:41,935 : INFO : Creating a fresh vocabulary\n",
      "2021-08-17 19:42:41,946 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=10 retains 0 unique words (0.0%% of original 0, drops 0)', 'datetime': '2021-08-17T19:42:41.936931', 'gensim': '4.0.1', 'python': '3.8.11 (default, Aug  6 2021, 09:57:55) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'prepare_vocab'}\n",
      "2021-08-17 19:42:41,947 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 0 word corpus (0.0%% of original 0, drops 0)', 'datetime': '2021-08-17T19:42:41.947902', 'gensim': '4.0.1', 'python': '3.8.11 (default, Aug  6 2021, 09:57:55) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'prepare_vocab'}\n",
      "2021-08-17 19:42:41,947 : INFO : deleting the raw counts dictionary of 0 items\n",
      "2021-08-17 19:42:41,948 : INFO : sample=0.001 downsamples 0 most-common words\n",
      "2021-08-17 19:42:41,948 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 0 word corpus (0.0%% of prior 0)', 'datetime': '2021-08-17T19:42:41.948899', 'gensim': '4.0.1', 'python': '3.8.11 (default, Aug  6 2021, 09:57:55) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'prepare_vocab'}\n",
      "2021-08-17 19:42:41,949 : INFO : estimated required memory for 0 words and 200 dimensions: 0 bytes\n",
      "2021-08-17 19:42:41,949 : INFO : resetting layer weights\n",
      "2021-08-17 19:42:41,950 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-08-17T19:42:41.949896', 'gensim': '4.0.1', 'python': '3.8.11 (default, Aug  6 2021, 09:57:55) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'build_vocab'}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "you must first build vocabulary before training the model",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-5648a59691d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMySentences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m model = gensim.models.Word2Vec(sentences,\n\u001b[0m\u001b[0;32m      9\u001b[0m                                \u001b[0mvector_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                                \u001b[0mwindow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sentences, corpus_file, vector_size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, epochs, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, comment, max_final_vocab)\u001b[0m\n\u001b[0;32m    417\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_corpus_sanity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m             self.train(\n\u001b[0m\u001b[0;32m    420\u001b[0m                 \u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m                 \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1034\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_training_sanity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1035\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_corpus_sanity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36m_check_training_sanity\u001b[1;34m(self, epochs, total_examples, total_words, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1523\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey_to_index\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# should be set by `build_vocab`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1524\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"you must first build vocabulary before training the model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1525\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"you must initialize vectors before training the model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: you must first build vocabulary before training the model"
     ]
    }
   ],
   "source": [
    "\n",
    "#if len(sys.argv) != 2:\n",
    "#    print(\"Please use python train_with_gensim.py data_path\")\n",
    "#    exit()\n",
    "data_path = \"../data/merged.gz\"\n",
    "begin = time()\n",
    "\n",
    "sentences = MySentences(data_path)\n",
    "model = gensim.models.Word2Vec(sentences,\n",
    "                               vector_size=200,\n",
    "                               window=10,\n",
    "                               min_count=10,\n",
    "                               workers=multiprocessing.cpu_count())\n",
    "model.save(\"data/model/word2vec_gensim\")\n",
    "model.wv.save_word2vec_format(\"data/model/word2vec_org\",\n",
    "                              \"data/model/vocabulary\",\n",
    "                              binary=False)\n",
    "\n",
    "end = time()\n",
    "print(\"Total procesing time: %d seconds\" % (end - begin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c188eac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
